import os
import asyncio
import logging
import numpy as np
import torch
import librosa
import joblib 
from aiogram import Bot, Dispatcher, types, F
from aiogram.filters import Command
from transformers import AutoFeatureExtractor, AutoModel

API_TOKEN = '8438809962:AAHBHiaoCB_WiXDqDhQPDX9XV6dpuogdH-8' 
MODEL_NAME = "ntu-spml/distilhubert"
CLASSIFIER_PATH = "model/hubert_emb_clf.joblib" 
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"

LABELS_MAP = {
    0: "üá∑üá∫ –†—É—Å—Å–∫–∏–π —è–∑—ã–∫",
    1: "üá¨üáß –ê–Ω–≥–ª–∏–π—Å–∫–∏–π —è–∑—ã–∫",
    2: "üá™üá∏ –ò—Å–ø–∞–Ω—Å–∫–∏–π —è–∑—ã–∫",
    3: "üá´üá∑ –§—Ä–∞–Ω—Ü—É–∑—Å–∫–∏–π —è–∑—ã–∫",
    4: "üá©üá™ –ù–µ–º–µ—Ü–∫–∏–π —è–∑—ã–∫"
}

logging.basicConfig(level=logging.INFO)

print(f"–ó–∞–≥—Ä—É–∑–∫–∞ Hubert-–º–æ–¥–µ–ª–∏ –Ω–∞ {DEVICE}...")
feature_extractor = AutoFeatureExtractor.from_pretrained(MODEL_NAME)
model = AutoModel.from_pretrained(MODEL_NAME)
model.eval()
model.to(DEVICE)

if os.path.exists(CLASSIFIER_PATH):
    print(f"–ó–∞–≥—Ä—É–∑–∫–∞ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞ –∏–∑ {CLASSIFIER_PATH}...")
    classifier = joblib.load(CLASSIFIER_PATH)
else:
    print(f"–§–∞–π–ª {CLASSIFIER_PATH} –Ω–µ –Ω–∞–π–¥–µ–Ω!")
    classifier = None

def load_audio(path):
    y, _ = librosa.load(path, sr=16000)
    return y

@torch.no_grad()
def extract_features(path):
    y = load_audio(path)

    inputs = feature_extractor(
        y,
        sampling_rate=16000,
        return_tensors="pt",
        padding=True
    )
    inputs = {k: v.to(DEVICE) for k, v in inputs.items()}

    outputs = model(**inputs, output_hidden_states=True)
    hidden_states = outputs.hidden_states
    
    layer = hidden_states[-1] 
    
    feats = layer.squeeze(0).cpu().numpy()  
    
    mean = feats.mean(axis=0)
    return mean

def get_prediction(path):
    features = extract_features(path)
    
    if classifier is None:
        raise ValueError("–ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω")

    features_reshaped = features.reshape(1, -1)
    
    prediction = classifier.predict(features_reshaped)[0]
    
    return prediction

bot = Bot(token=API_TOKEN)
dp = Dispatcher()

@dp.message(Command("start"))
async def cmd_start(message: types.Message):
    await message.answer(
        "–ü—Ä–∏–≤–µ—Ç! –Ø –±–æ—Ç-–∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä –∞—É–¥–∏–æ. ü§ñ\n\n"
        "–ü—Ä–∏—à–ª–∏ –º–Ω–µ –≥–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ, —è –ø—Ä–æ–ø—É—â—É –µ–≥–æ —á–µ—Ä–µ–∑ –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏"
        f"–∏ —Å–∫–∞–∂—É, –Ω–∞ –∫–∞–∫–æ–º —è–∑—ã–∫–µ —ç—Ç–æ —Å–æ–æ–±—â–µ–Ω–∏–µ!"
    )

@dp.message(F.voice)
async def handle_voice(message: types.Message):
    status_msg = await message.reply("üéß –°–ª—É—à–∞—é –∏ –∞–Ω–∞–ª–∏–∑–∏—Ä—É—é...")
    
    file_id = message.voice.file_id
    file = await bot.get_file(file_id)
    temp_filename = f"voice_{file_id}.ogg"

    try:
        await bot.download_file(file.file_path, temp_filename)

        result_class = await asyncio.to_thread(get_prediction, temp_filename)

        label_text = LABELS_MAP.get(result_class, str(result_class))

        await status_msg.edit_text(
            f"*–ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω!*\n\n"
            f"**–†–µ–∑—É–ª—å—Ç–∞—Ç:** `{label_text}`",
            parse_mode="Markdown"
        )

    except Exception as e:
        logging.error(f"Error: {e}")
        await status_msg.edit_text("–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏.")
    
    finally:
        if os.path.exists(temp_filename):
            os.remove(temp_filename)

async def main():
    await dp.start_polling(bot)

if __name__ == "__main__":
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        print("–ë–æ—Ç –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
